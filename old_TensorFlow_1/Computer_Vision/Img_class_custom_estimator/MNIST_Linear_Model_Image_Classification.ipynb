{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Linear_Model Image Classification ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danr17/MLDLTF_coding/blob/master/Vision/MNIST_Linear_Model_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iQNsrvvG5CnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Credits to Google training,  Advanced Machine Learning with Tensorflow on GCP"
      ]
    },
    {
      "metadata": {
        "id": "ZXT1WAcQ3_wN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7415439e-4740-42d6-fa50-12e562e7969f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kJsT2dnq6wKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "96ad28f5-e0f9-4549-da27-87eb69c88b48"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets(\"mnist/data\", one_hot=True, reshape=False)\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "(55000, 28, 28, 1)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yydq8gRt7Vw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a799d0c9-d2ca-420e-a94c-3f512daf0adb"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Apq4Trb7nbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HEIGHT=28\n",
        "WIDTH=28\n",
        "NCLASSES=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZghnGXpf88Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "010e61ec-f7b3-4911-a234-43637542215c"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "IMGNO=23\n",
        "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1334ed8a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDIglABgQSwAwIJYAYEAsAcDg/wBTsA33QsDYSAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1334f00da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "O1fspAy-9dln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the Linear model low level or using tf.layers API**"
      ]
    },
    {
      "metadata": {
        "id": "nZ3ZbjQB9LKb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_model(img):\n",
        "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) # flatten\n",
        "  W = tf.get_vairable(\"W\", [HEIGHT*WIDTH, NCLASSES], initializer=tf.truncated_normal_initilizer(stddev=0.1, seed=1))\n",
        "  b = tf.get_variable(\"b\", NCLASSES, initializer=tf.zeros_initializer)\n",
        "  ylogits = tf.matmul(X,W) + b\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G2-YihJr_mBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_model(img):\n",
        "  X=tf.reshape(img,[-1, HEIGHT*WIDTH])\n",
        "  ylogits = tf.layers.dense(X,NCLASSES,activation = None)\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTGkD3RhP3Z2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Result for Linear: Saving dict for global step 1000: accuracy = 0.9177, global_step = 1000, loss = 0.29642856"
      ]
    },
    {
      "metadata": {
        "id": "fhQRXzH1AmTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write Input Functions**"
      ]
    },
    {
      "metadata": {
        "id": "8dDzS_d6Aink",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = {'image':mnist.train.images},\n",
        "    y = mnist.train.labels,\n",
        "    batch_size = 100,\n",
        "    num_epochs = None,\n",
        "    shuffle = True,\n",
        "    queue_capacity = 5000\n",
        ")\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'image':mnist.test.images},\n",
        "    y=mnist.test.labels,\n",
        "    batch_size = 100,\n",
        "    num_epochs = 1,\n",
        "    shuffle = False,\n",
        "    queue_capacity = 5000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_CfFkm4yArtd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_fn():\n",
        "  inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
        "  features = inputs # no change\n",
        "  return tf.estimator.export.ServingInputReceiver(features, inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4T5np4XpDxGR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write a custom estimator to accomodate Linear, DNN and CNN models**"
      ]
    },
    {
      "metadata": {
        "id": "fE9J8sNzDp4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_classifier(features, labels, mode, params):\n",
        "  ylogits, nclasses = linear_model(features['image'])\n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels=labels))\n",
        "    evalmetrics ={'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(), learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        "  return tf.estimator. EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabbilities\": probabilities, \"classes\": classes},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={\"classes\": tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classes\": classes})}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiRGnlZ6HqyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, hparams):\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier, params = hparams, model_dir = output_dir)\n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn, max_steps = hparams['train_steps'])\n",
        "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn, steps = None, exporters = exporter)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DjN9OIkL_5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1095
        },
        "outputId": "37635683-bef6-4998-a90a-1ac26f413a4b"
      },
      "cell_type": "code",
      "source": [
        "OUTDIR = 'mnist/learned'\n",
        "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh\n",
        "\n",
        "hparams = {'train_steps': 1000, 'learning_rate': 0.01}\n",
        "train_and_evaluate(OUTDIR, hparams)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'mnist/learned', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f132ef15a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3958416, step = 1\n",
            "INFO:tensorflow:global_step/sec: 362.773\n",
            "INFO:tensorflow:loss = 0.2628791, step = 101 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.021\n",
            "INFO:tensorflow:loss = 0.21158193, step = 201 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.421\n",
            "INFO:tensorflow:loss = 0.26444635, step = 301 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 428.55\n",
            "INFO:tensorflow:loss = 0.5665085, step = 401 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 435.474\n",
            "INFO:tensorflow:loss = 0.3038096, step = 501 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 415.396\n",
            "INFO:tensorflow:loss = 0.3529625, step = 601 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 427.407\n",
            "INFO:tensorflow:loss = 0.20175448, step = 701 (0.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.346\n",
            "INFO:tensorflow:loss = 0.35691088, step = 801 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.597\n",
            "INFO:tensorflow:loss = 0.22329712, step = 901 (0.222 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-01-10-10:10:50\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-01-10-10:10:51\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9177, global_step = 1000, loss = 0.29642856\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: mnist/learned/export/Servo/temp-b'1547115051'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.25919822.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i2uZwhZUPi5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}