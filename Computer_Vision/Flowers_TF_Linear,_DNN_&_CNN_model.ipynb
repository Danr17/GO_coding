{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers TF Linear, DNN & CNN model ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danr17/TensorFlow_coding/blob/master/Computer_Vision/Flowers_TF_Linear%2C_DNN_%26_CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iQNsrvvG5CnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Credits to Google training,  Advanced Machine Learning with Tensorflow on GCP"
      ]
    },
    {
      "metadata": {
        "id": "ZXT1WAcQ3_wN",
        "colab_type": "code",
        "outputId": "803bb1b9-1e52-4932-9f72-2f3b9581f765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Apq4Trb7nbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LIST_OF_LABELS='daisy,dandelion,roses,sunflowers,tulips'.split(',')\n",
        "HEIGHT=299\n",
        "WIDTH=299\n",
        "NUM_CHANNELS=3\n",
        "NCLASSES=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1fspAy-9dln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the Linear model low level or using tf.layers API**"
      ]
    },
    {
      "metadata": {
        "id": "G2-YihJr_mBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def linear_model(img, mode, hparams):\n",
        "  X=tf.reshape(img,[-1, HEIGHT*WIDTH*NUM_CHANNELS])\n",
        "  ylogits = tf.layers.dense(X,NCLASSES,activation = None)\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTGkD3RhP3Z2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Result for Linear: ?"
      ]
    },
    {
      "metadata": {
        "id": "hDq8AMd0ftlQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the DNN model**"
      ]
    },
    {
      "metadata": {
        "id": "OJQf9gAwfzkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dnn_model(img, mode, hparams):\n",
        "  X= tf.reshape(img,[-1,HEIGHT*WIDTH*NUM_CHANNELS])\n",
        "  h1 = tf.layers.dense(X, 300, activation = tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation = tf.nn.relu)\n",
        "  h3 = tf.layers.dense(h2, 30, activation = tf.nn.relu)\n",
        "  ylogits = tf.layers.dense(h3, NCLASSES, activation = None)\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "unAeMRh0xTgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Results for DNN: ?"
      ]
    },
    {
      "metadata": {
        "id": "FG8DXtsIlTfG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define DNN Dropout model**"
      ]
    },
    {
      "metadata": {
        "id": "kLSze62ClbpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dnn_dropout_model(img, mode, hparams):\n",
        "  dprob = hparams.get('dprob', 0.1)\n",
        "  \n",
        "  X= tf.reshape(img,[-1,HEIGHT*WIDTH*NUM_CHANNELS])\n",
        "  h1 = tf.layers.dense(X, 300, activation = tf.nn.relu)\n",
        "  h2 = tf.layers.dense(h1, 100, activation = tf.nn.relu)\n",
        "  h3 = tf.layers.dense(h2, 30, activation = tf.nn.relu)\n",
        "  h3d = tf.layers.dropout(h3, rate=dprob, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "  ylogits = tf.layers.dense(h3d, NCLASSES, activation = None)\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zcZXn7dyjA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Results for DNN with DropOut: "
      ]
    },
    {
      "metadata": {
        "id": "XuHksjUNljw_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define CNN model**"
      ]
    },
    {
      "metadata": {
        "id": "-l_Dnjx-lmsH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model(img, mode, haparams):\n",
        "  ksize1 = hparams.get('ksize1', 5)\n",
        "  ksize2 = hparams.get('ksize2', 5)\n",
        "  nfil1 = hparams.get('nfil1', 10)\n",
        "  nfil2 = hparams.get('nfil2', 20)\n",
        "  dprob = hparams.get('drop', 0.25)\n",
        "  \n",
        "  c1 = tf.layers.conv2d(img, filters=nfil1, kernel_size=ksize1, strides=1, padding='same', activation=tf.nn.relu) \n",
        "  p1 = tf.layers.max_pooling2d(c1, pool_size=2, strides=2) \n",
        "  c2 = tf.layers.conv2d(p1, filters=nfil2, kernel_size=ksize2, strides=1, padding='same', activation=tf.nn.relu) \n",
        "  p2 = tf.layers.max_pooling2d(c2, pool_size=2, strides=2) \n",
        "  \n",
        "  outlen = p2.shape[1]*p2.shape[2]*p2.shape[3] \n",
        "  p2flat = tf.reshape(p2, [-1, outlen])\n",
        "  \n",
        "  h3 = tf.layers.dense(p2flat, 300, activation=tf.nn.relu)\n",
        "  h3d = tf.layers.dropout(h3, rate=dprob, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
        "  return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DrMa21i54HWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Results for CNN: ?"
      ]
    },
    {
      "metadata": {
        "id": "fhQRXzH1AmTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write Input Functions**"
      ]
    },
    {
      "metadata": {
        "id": "iaDyv4u3eGca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_and_preprocess_with_augment(image_bytes, label=None):\n",
        "  return read_and_preprocess(image_bytes, label, augment=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-CVuQWofVEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_and_preprocess(image_bytes, label=None, augment= False):\n",
        "  # decode the image, end up with pixel values witch are in -1, 1 range\n",
        "  image = tf.image.decode_jpeg(image_bytes, channels=NUM_CHANNELS)\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32) # 0 - 1\n",
        "  image = tf.expand_dims(image, 0) # resize with batches\n",
        "  \n",
        "  if augment:\n",
        "    image = tf.image.resize_bilinear(image, [HEIGHT+10, WIDTH+10], align_corners=False)\n",
        "    image = tf.squeeze(image) # remove batch dimension\n",
        "    image = tf.random_crop(image, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=63.0/255.0)\n",
        "    image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
        "  else:\n",
        "    image = tf.image.resize_bilinear(image, [HEIGHT, WIDTH], align_corners=False)\n",
        "    image = tf.squeeze(image) # remove batch dimension\n",
        "    \n",
        "  # pizel values are in [0,1] range, convert to [-1,1]\n",
        "  image = tf.subtract(image, 0.5)\n",
        "  image = tf.multiply(image, 2.0)\n",
        "  return {'image': image}, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_edc_PzikLzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_fn():\n",
        "  # handles one image at a time\n",
        "  feature_placeholders = {'image_bytes': tf.placeholder(tf.string, shape())}\n",
        "  image, _ = read_and_preprocess(tf.squeeze(feature_placeholders['image_bytes']))\n",
        "  image['image'] = tf.expand_dims(image['image'], 0)\n",
        "  return tf.estimator.export.ServingInputReceive(image, feature_placeholders)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQlnygxNlnrX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_input_fn(csv_of_filenames, batch_size, mode, augment=False):\n",
        "  def _input_fn():\n",
        "    def decode_csv(csv_row):\n",
        "      filename, label = tf.decode_csv(csv_row, record_defaults=[[''],['']])\n",
        "      image_bytes = tf.read_file(filename)\n",
        "      return image_bytes, label\n",
        "    \n",
        "    #create tf.data.dataset from filename\n",
        "    dataset = tf.data.TextLineDataset(csv_of_filenames).map(decode_csv)\n",
        "    \n",
        "    if augment:\n",
        "      dataset = dataset.map(read_and_preprocess_with_augment)\n",
        "    else:\n",
        "      dataset = dataset.map(read_and_preprocess)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      num_epochs = None\n",
        "      dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
        "    else:\n",
        "      num_epochs = 1\n",
        "    \n",
        "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4T5np4XpDxGR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Write a custom estimator to accomodate Linear, DNN and CNN models**"
      ]
    },
    {
      "metadata": {
        "id": "fE9J8sNzDp4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_classifier(features, labels, mode, params):\n",
        "  model_functions = {'linear': linear_model, 'dnn': dnn_model, 'dnn_dropout': dnn_dropout_model, 'cnn': cnn_model}\n",
        "  model_function = model_functions[params['model']]\n",
        "  ylogits, nclasses = model_function(features['image'], mode, params)\n",
        "  \n",
        "  probabilities = tf.nn.softmax(ylogits)\n",
        "  class_int = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
        "  class_str = tf.gather(LIST_OF_LABELS, tf.cast(class_int, tf.int32))\n",
        "  \n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "    # convert string label to int\n",
        "    labels_table = tf.contrib.lookup.index_table_from_tensor(tf.constant(LIST_OF_LABELS))\n",
        "    labels = labels_table.lookup(labels)\n",
        "    \n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels=tf.one_hot(labels, nclasses)))\n",
        "    evalmetrics ={'accuracy': tf.metrics.accuracy(class_int, labels)}\n",
        "                                                  \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # this is needed for batch normalization, but has no effct otherwise\n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      with tf.control_dependencies(update_ops):\n",
        "        train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(), learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
        "    else:\n",
        "      train_op = None\n",
        "  else:\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    evalmetrics = None\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions={\"probabbilities\": probabilities, \"classid\": class_int, \"class\": class_str},\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=evalmetrics,\n",
        "        export_outputs={\"classes\": tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classid\": class_int, \"class\": class_str})}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiRGnlZ6HqyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, hparams):\n",
        "  EVAL_INTERVAL = 300\n",
        "  estimator = tf.estimator.Estimator(model_fn = image_classifier, params = hparams, config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL), model_dir = output_dir)\n",
        "  train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(hparams['train_data_path'], hparams['batch_size'], mode = tf.estimator.ModeKeys.TRAIN, augment = hparams['augment']), max_steps = hparams['train_steps'])\n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(hparams['eval_data_path'], hparams['batch_size'], mode = tf.estimator.ModeKeys.TRAIN), steps = None, exporters = exporter, start_delay_secs = EVAL_INTERVAL, throttle_secs = EVAL_INTERVAL)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgSmjXzk5wUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r gs://cloud-ml-data/img/flower_photos/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zk8u0zu_7qKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "862faf3c-4dea-4396-dd42-aa3a6ecd74d0"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_data.csv\t\t flowers_200_presplit.zip      roses.zip\n",
            "daisy\t\t\t flowers_200_unlabeled.zip     sample_data\n",
            "daisy.zip\t\t flowers_full_with_csv.zip     sunflowers\n",
            "dandelion\t\t inception_v3_2016_08_28.ckpt  sunflowers.zip\n",
            "dandelion.zip\t\t LICENSE.txt\t\t       train_set.csv\n",
            "dict.txt\t\t mnist\t\t\t       tulips\n",
            "eval_set.csv\t\t open_image_inception_v3.ckpt  tulips.zip\n",
            "flowers_200_csv.zip\t README.txt\n",
            "flowers_200_folders.zip  roses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1BE1MkLD-ARi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#!sed -i 's/gs\\:\\/\\/cloud\\-ml\\-data\\/img\\/flower_photos\\//\\/content\\//' train_set.csv\n",
        "#!sed -i 's/gs\\:\\/\\/cloud\\-ml\\-data\\/img\\/flower_photos\\//\\/content\\//' eval_set.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DjN9OIkL_5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "OUTDIR = 'flowers/learned'\n",
        "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh\n",
        "\n",
        "hparams = {'model': 'linear','train_steps': 100, 'learning_rate': 0.01, 'batch_size': 100, 'train_data_path': 'train_set.csv', 'eval_data_path': 'eval_set.csv', 'augment': False}\n",
        "train_and_evaluate(OUTDIR, hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}